import os
import logging
from dotenv import load_dotenv
from langchain.prompts import PromptTemplate
from langchain_openai import AzureChatOpenAI
from langchain.docstore.document import Document
from langchain.chains.summarize import load_summarize_chain

# Load environment variables from a .env file.
load_dotenv()

# Configure logging to log both to a file and the console.
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(os.path.join(os.getcwd(), "Ingestion_logs.log")),
        logging.StreamHandler(),
    ],
)

# Initialize the Azure OpenAI language model with specific settings.
llm_gpt = AzureChatOpenAI(
    openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"],  # API version from environment variables.
    azure_deployment=os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"],  # Deployment name from environment variables.
    max_retries=20,  # Maximum number of retries for the API call.
)

# Define the prompt template for generating detailed summaries.
map_prompt_template = """
                      Write a detailed and elaborated summary of the following text that includes the main points and any important details.
                      Aim for a summary length of approximately 1500 words.
                      {text}
                      """
map_prompt = PromptTemplate(template=map_prompt_template, input_variables=["text"])

# Define the prompt template for combining summaries into a comprehensive summary.
combine_prompt_template = """
                      Write a comprehensive summary of the following text delimited by triple backquotes.
                      Aim for a summary length of approximately 800 words without missing the important information in the text.
                      ```{text}```
                      COMPREHENSIVE SUMMARY:
                      """
combine_prompt = PromptTemplate(
    template=combine_prompt_template, input_variables=["text"]
)

# Load the summarization chain using the map-reduce approach with the defined prompts.
summary_chain = load_summarize_chain(
    llm_gpt,
    chain_type="map_reduce",  # Specify the map-reduce chain type for summarization.
    map_prompt=map_prompt,  # Use the detailed summary prompt for the map step.
    combine_prompt=combine_prompt,  # Use the comprehensive summary prompt for the reduce step.
)

def create_summary(batch_summary):
    """
    Creates a comprehensive summary from a batch of text summaries.

    Parameters:
    batch_summary (dict): A dictionary where each value is a text summary to be combined.

    Returns:
    str: The resulting summary generated by the summarization chain.

    Logs:
    Errors are logged if the summary creation process fails.
    """
    try:
        # Accumulate all the summaries into one string.
        accumulated_value = " ".join(batch_summary.values())

        # Create a Document object with the accumulated text.
        doc = Document(page_content=accumulated_value)

        # Invoke the summary chain on the Document object to generate the final summary.
        summary_result = summary_chain.invoke([doc])

        return summary_result  # Return the generated summary.
    except Exception as e:
        # Log an error if something goes wrong during summary creation.
        logging.error(f"Failed to create summary. {e}")

