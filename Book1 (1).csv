output_csv = "GV_Test_OCR_50_ollama_image.csv"
                    embeddings = OllamaEmbeddings(
                        base_url="http://10.0.0.4:11434", model="nomic-embed-text:latest"
                    )
                    vectorstore = Chroma(
                        collection_name="GV_Test_OCR_50_ollama",
                        client=CHROMA_CLIENT,
                        embedding_function=embeddings,
                    )
                    docstore_path = os.path.join(
                        "/home/Mayank.Sharma/GV_Test/retriever/ingestion/GV_Test_OCR_50_ollama.pkl"
                    )
                    with open(docstore_path, "rb") as file:
                        loaded_docstore = pickle.load(file)
                    retriever = MultiVectorRetriever(
                        vectorstore=vectorstore,
                        docstore=loaded_docstore,
                        id_key="GV_Test_OCR_50_ollama",
                    )
                    chain_gpt = create_multi_modal_chain_gpt_1(retriever)
                    chain_llava = create_multi_modal_chain_llava_1(retriever)
                    for idx, question in enumerate(questions, start=1):
                        print(f"Processing question: {question}")

                        (
                            global_sources,
                            global_sources_link,
                            global_ids,
                            global_text_chunks,
                            global_image_chunks,
                        ) = ([], [], [], [], [])

                        start_time_gpt = time.time()
                        answer_gpt = chain_gpt.invoke(question)
                        sources_gpt = global_sources.copy()
                        sources_gpt_link = global_sources_link.copy()
                        end_time_gpt = time.time()
                        time_gpt = end_time_gpt - start_time_gpt
                        save_chunks(
                            "Chunks_Global_ChatQA_image",
                            question,
                            global_text_chunks,
                            global_image_chunks,
                            "GPT",
                        )

                        (
                            global_sources,
                            global_sources_link,
                            global_ids,
                            global_text_chunks,
                            global_image_chunks,
                        ) = ([], [], [], [], [])

                        start_time_llava = time.time()
                        answer_llava = chain_llava.invoke(question)
                        sources_llava = global_sources.copy()
                        sources_llava_link = global_sources_link.copy()
                        end_time_llava = time.time()
                        time_llava = end_time_llava - start_time_llava
                        save_chunks(
                            "Chunks_Global_ChatQA_image",
                            question,
                            global_text_chunks,
                            global_image_chunks,
                            "LLaVa",
                        )

                        results = {
                            "question": question,
                            "answer_gpt": answer_gpt,
                            "answer_llava": answer_llava,
                            "sources_gpt": sources_gpt,
                            "sources_gpt_link": sources_gpt_link,
                            "sources_llava": sources_llava,
                            "sources_llava_link": sources_llava_link,
                            "time_gpt": time_gpt,
                            "time_llava": time_llava,
                        }

                        df = pd.DataFrame([results])

                        if os.path.exists(output_csv):
                            df.to_csv(output_csv, mode="a", header=False, index=False)
                        else:
                            df.to_csv(output_csv, mode="w", header=True, index=False)
